{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://www.kaggle.com/code/alexpengxiao/preprocessing-model-averaging-by-xgb-lgb-1-39/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing, model averaging by xgb + lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we preprocessed the data and feed the data to gradient boosting tree models, and got 1.39 on public leaderboard.\n",
    "\n",
    "the workflow is as follows:\n",
    "\n",
    "##### 1. Data preprocessing. The purpose of data preprocessing is to achieve higher time/space efficiency. What we did includes round, constant features removal, duplicate features removal, insignificant features removal, etc. The key here is to ensure the preprocessing shall not hurt the accuracy.\n",
    "##### 2. Feature transform. The purpose of feature transform is to help the models to better grasp the information in the data, and fight overfitting. What we did includes dropping features which \"live\" on different distributions on training/testing set, adding statistical features, adding low-dimensional representation as features.\n",
    "##### 3. Modeling. We used 2 models: xgboost and lightgbm. We averaged the 2 models for the final prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### step 1: load train & test data, drop duplicate columns, round the features to NUM_OF_DECIMALS decimals. here NUM_OF_DECIMALS is a experience value which can be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, FastICA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.manifold import TSNE\n",
    "import gc\n",
    "#Plotting\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load The Files and Get a Brief Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "train_df = pd.read_csv('/Users/sangth/Desktop/USF_Springboard/Capstone_2/Dataset/santander-value-prediction-challenge/train.csv')\n",
    "test_df = pd.read_csv('/Users/sangth/Desktop/USF_Springboard/Capstone_2/Dataset/santander-value-prediction-challenge/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d6aaf2</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fbd867</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0027d6b71</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028cbf45</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002a68644</td>\n",
       "      <td>14400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4993 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID      target  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  \\\n",
       "0  000d6aaf2  38000000.0        0.0          0        0.0          0   \n",
       "1  000fbd867    600000.0        0.0          0        0.0          0   \n",
       "2  0027d6b71  10000000.0        0.0          0        0.0          0   \n",
       "3  0028cbf45   2000000.0        0.0          0        0.0          0   \n",
       "4  002a68644  14400000.0        0.0          0        0.0          0   \n",
       "\n",
       "   2f0771a37  30347e683  d08d1fbe3  6ee66e115  ...  3ecc09859  9281abeea  \\\n",
       "0          0          0          0          0  ...        0.0        0.0   \n",
       "1          0          0          0          0  ...        0.0        0.0   \n",
       "2          0          0          0          0  ...        0.0        0.0   \n",
       "3          0          0          0          0  ...        0.0        0.0   \n",
       "4          0          0          0          0  ...        0.0        0.0   \n",
       "\n",
       "   8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  fb36b89d9  \\\n",
       "0        0.0          0          0          0          0          0   \n",
       "1        0.0          0          0          0          0          0   \n",
       "2        0.0          0          0          0          0          0   \n",
       "3        0.0          0          0          0          0          0   \n",
       "4        0.0          0          0          0          0          0   \n",
       "\n",
       "   7e293fbaf  9fc776466  \n",
       "0          0          0  \n",
       "1          0          0  \n",
       "2          0          0  \n",
       "3          0          0  \n",
       "4          0          0  \n",
       "\n",
       "[5 rows x 4993 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000137c73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00021489f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004d7953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00056a333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00056d8eb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4992 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  2f0771a37  \\\n",
       "0  000137c73        0.0        0.0        0.0        0.0        0.0   \n",
       "1  00021489f        0.0        0.0        0.0        0.0        0.0   \n",
       "2  0004d7953        0.0        0.0        0.0        0.0        0.0   \n",
       "3  00056a333        0.0        0.0        0.0        0.0        0.0   \n",
       "4  00056d8eb        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   30347e683  d08d1fbe3  6ee66e115  20aa07010  ...  3ecc09859  9281abeea  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  fb36b89d9  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   7e293fbaf  9fc776466  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        0.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "\n",
       "[5 rows x 4992 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set Up Train & Test X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop([\"ID\", \"target\"], axis=1)\n",
    "y_train = np.log1p(train_df[\"target\"].values)\n",
    "\n",
    "X_test = test_df.drop([\"ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4459 entries, 0 to 4458\n",
      "Columns: 4993 entries, ID to 9fc776466\n",
      "dtypes: float64(1845), int64(3147), object(1)\n",
      "memory usage: 169.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49342 entries, 0 to 49341\n",
      "Columns: 4992 entries, ID to 9fc776466\n",
      "dtypes: float64(4991), object(1)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for NaN values and removing constant features in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Features with NaN Values = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Train Features with NaN Values = \" + str(train_df.columns[train_df.isnull().sum() != 0].size))\n",
    "if (train_df.columns[train_df.isnull().sum() != 0].size):\n",
    "    print(\"Features with NaN => {}\".format(list(train_df.columns[train_df.isnull().sum() != 0])))\n",
    "    train_df[train_df.columns[train_df.isnull().sum() != 0]].isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2362 features of 4491 have zeroes in 99% or more samples.\n",
      "2868 features of 4491 have zeroes in 98% or more samples.\n",
      "3315 features of 4491 have zeroes in 97% or more samples.\n",
      "3794 features of 4491 have zeroes in 96% or more samples.\n",
      "3992 features of 4491 have zeroes in 95% or more samples.\n",
      "\n",
      "Train shape: (4459, 2123)\n",
      "Test shape: (49342, 2123)\n"
     ]
    }
   ],
   "source": [
    "zero_count = []\n",
    "for col in X_train.columns[2:]:\n",
    "    zero_count.append([i[1] for i in list(X_train[col].value_counts().items()) if i[0] == 0][0])\n",
    "    \n",
    "print('{0} features of 4491 have zeroes in 99% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.99])))\n",
    "print('{0} features of 4491 have zeroes in 98% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.98])))\n",
    "print('{0} features of 4491 have zeroes in 97% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.97])))\n",
    "print('{0} features of 4491 have zeroes in 96% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.96])))\n",
    "print('{0} features of 4491 have zeroes in 95% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.95])))\n",
    "\n",
    "cols_to_drop = [col for col in X_train.columns[2:] if [i[1] for i in list(X_train[col].value_counts().items()) if i[0] == 0][0] >= 4459 * 0.98]\n",
    "\n",
    "X_train.drop(cols_to_drop, axis=1, inplace=True)\n",
    "X_test.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed `0` Constant Columns\n",
      "\n",
      "[]\n",
      "\n",
      "Train shape: (4459, 2123)\n",
      "Test shape: (49342, 2123)\n"
     ]
    }
   ],
   "source": [
    "colsToRemove = []\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].std() == 0: \n",
    "        colsToRemove.append(col)\n",
    "        \n",
    "# remove constant columns in the training set\n",
    "train_df.drop(colsToRemove, axis=1, inplace=True)\n",
    "\n",
    "# remove constant columns in the test set\n",
    "test_df.drop(colsToRemove, axis=1, inplace=True) \n",
    "\n",
    "print(\"Removed `{}` Constant Columns\\n\".format(len(colsToRemove)))\n",
    "print(colsToRemove)\n",
    "print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing Duplicated Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed `0` Duplicate Columns\n",
      "\n",
      "{}\n",
      "\n",
      "Train shape: (4459, 2123)\n",
      "Test shape: (49342, 2123)\n"
     ]
    }
   ],
   "source": [
    "colsToRemove = []\n",
    "colsScaned = []\n",
    "dupList = {}\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "for i in range(len(columns)-1):\n",
    "    v = X_train[columns[i]].values\n",
    "    dupCols = []\n",
    "    for j in range(i+1,len(columns)):\n",
    "        if np.array_equal(v, X_train[columns[j]].values):\n",
    "            colsToRemove.append(columns[j])\n",
    "            if columns[j] not in colsScaned:\n",
    "                dupCols.append(columns[j]) \n",
    "                colsScaned.append(columns[j])\n",
    "                dupList[columns[i]] = dupCols\n",
    "                \n",
    "# remove duplicate columns in the training set\n",
    "X_train.drop(colsToRemove, axis=1, inplace=True) \n",
    "\n",
    "# remove duplicate columns in the testing set\n",
    "X_test.drop(colsToRemove, axis=1, inplace=True)\n",
    "\n",
    "print(\"Removed `{}` Duplicate Columns\\n\".format(len(dupList)))\n",
    "print(dupList)\n",
    "\n",
    "print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop Sparse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_sparse(train, test):\n",
    "    flist = [x for x in train.columns if not x in ['ID','target']]\n",
    "    for f in flist:\n",
    "        if len(np.unique(train[f]))<2:\n",
    "            train.drop(f, axis=1, inplace=True)\n",
    "            test.drop(f, axis=1, inplace=True)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train shape: (4459, 2123)\n",
      "Test shape: (49342, 2123)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = drop_sparse(X_train, X_test)\n",
    "\n",
    "print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumzeros and Sumvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_SumZeros(train, test, features):\n",
    "    flist = [x for x in train.columns if not x in ['ID','target']]\n",
    "    if 'SumZeros' in features:\n",
    "        train.insert(1, 'SumZeros', (train[flist] == 0).astype(int).sum(axis=1))\n",
    "        test.insert(1, 'SumZeros', (test[flist] == 0).astype(int).sum(axis=1))\n",
    "    flist = [x for x in train.columns if not x in ['ID','target']]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test = add_SumZeros(X_train, X_test, ['SumZeros'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_SumValues(train, test, features):\n",
    "    flist = [x for x in train.columns if not x in ['ID','target']]\n",
    "    if 'SumValues' in features:\n",
    "        train.insert(1, 'SumValues', (train[flist] != 0).astype(int).sum(axis=1))\n",
    "        test.insert(1, 'SumValues', (test[flist] != 0).astype(int).sum(axis=1))\n",
    "    flist = [x for x in train.columns if not x in ['ID','target']]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test = add_SumValues(X_train, X_test, ['SumValues'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_OtherAgg(train, test, features):\n",
    "    flist = [x for x in train.columns if not x in ['ID','target','SumZeros','SumValues']]\n",
    "    if 'OtherAgg' in features:\n",
    "        train['Mean'] = train.mean(axis=1)\n",
    "        train['Median'] = train.median(axis=1)\n",
    "        train['Mode'] = train.mode(axis=1)\n",
    "        train['Max'] = train.max(axis=1)\n",
    "        train['Var'] = train.var(axis=1)\n",
    "        train['Std'] = train.std(axis=1)\n",
    "        \n",
    "        test['Mean'] = test.mean(axis=1)\n",
    "        test['Median'] = test.median(axis=1)\n",
    "        test['Mode'] = test.mode(axis=1)\n",
    "        test['Max'] = test.max(axis=1)\n",
    "        test['Var'] = test.var(axis=1)\n",
    "        test['Std'] = test.std(axis=1)\n",
    "    flist = [x for x in train.columns if not x in ['ID','target','SumZeros','SumValues']]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X_Tr,Xte):\n",
    "    flist = [x for x in X_Tr.columns if not x in ['ID','target']]\n",
    "    flist_kmeans = []\n",
    "    for ncl in range(2,11):\n",
    "        cls = KMeans(n_clusters=ncl)\n",
    "        cls.fit_predict(X_train[flist].values)\n",
    "        X_Tr['kmeans_cluster_'+str(ncl)] = cls.predict(X_Tr[flist].values)\n",
    "        Xte['kmeans_cluster_'+str(ncl)] = cls.predict(Xte[flist].values)\n",
    "        flist_kmeans.append('kmeans_cluster_'+str(ncl))\n",
    "    print(flist_kmeans)\n",
    "    \n",
    "    return X_Tr,Xte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X_Tr,Xte):\n",
    "    flist = [x for x in X_Tr.columns if not x in ['ID','target']]\n",
    "    n_components = 20\n",
    "    flist_pca = []\n",
    "    pca = PCA(n_components=n_components)\n",
    "    x_train_projected = pca.fit_transform(StandardScaler(X_Tr[flist], axis=0))\n",
    "    x_test_projected = pca.transform(StandardScaler(X_test[flist], axis=0))\n",
    "    for npca in range(0, n_components):\n",
    "        X_Tr.insert(1, 'PCA_'+str(npca+1), x_train_projected[:, npca])\n",
    "        Xte.insert(1, 'PCA_'+str(npca+1), x_test_projected[:, npca])\n",
    "        flist_pca.append('PCA_'+str(npca+1))\n",
    "    print(flist_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train shape: (4459, 2123)\n",
      "Test shape: (49342, 2123)\n"
     ]
    }
   ],
   "source": [
    "print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start decomposition process...\n",
      "PCA\n",
      "[0.05845484 0.0383209  0.03829271 0.03828013 0.03825617 0.03824973\n",
      " 0.03823006 0.03821477 0.0381978  0.03816147 0.02786177 0.02214392\n",
      " 0.01657821 0.0130679  0.01158438 0.01150749 0.01133923 0.01121784\n",
      " 0.01113108 0.01036719 0.00946003 0.00854243 0.00795691 0.00719521\n",
      " 0.00695735 0.00646891 0.00634419 0.006164   0.00599398 0.0059037\n",
      " 0.00575507 0.00565423 0.00541038 0.0053179  0.00497676 0.00483699\n",
      " 0.00471673 0.0045214  0.00443197 0.00438417 0.00427236 0.00419191\n",
      " 0.00409204 0.0040596  0.00392973 0.00381137 0.00380971 0.00369276\n",
      " 0.00360305 0.00348218 0.00341211 0.00322577 0.00320448 0.00308076\n",
      " 0.00296015 0.00288679 0.0027445  0.00263927 0.0026055  0.00257357\n",
      " 0.00252259 0.00248433 0.0024462  0.00232029 0.00231383 0.00225798\n",
      " 0.00222129 0.00218594 0.00212406 0.0020847  0.0020516  0.00199384\n",
      " 0.00191684 0.00184879 0.00181508 0.00177521 0.00175046 0.00172354\n",
      " 0.00170877 0.00168471 0.00165735 0.00160635 0.00159153 0.00154126\n",
      " 0.00153326 0.00150486 0.00144776 0.00142156 0.00141062 0.00140296\n",
      " 0.00136964 0.00136363 0.00132655 0.00129932 0.00127745 0.0012323\n",
      " 0.00121637]\n",
      "tSVD\n",
      "ICA\n",
      "GRP\n",
      "SRP\n",
      "Append decomposition components to datasets...\n",
      "\n",
      "Train shape: (4459, 2608)\n",
      "Test shape: (49342, 2608)\n"
     ]
    }
   ],
   "source": [
    "PERC_TRESHOLD = 0.98   ### Percentage of zeros in each feature ###\n",
    "N_COMP = 97            ### Number of decomposition components ###\n",
    "\n",
    "print(\"\\nStart decomposition process...\")\n",
    "print(\"PCA\")\n",
    "pca = PCA(n_components=N_COMP, random_state=17)\n",
    "pca_results_train = pca.fit_transform(X_train)\n",
    "pca_results_test = pca.transform(X_test)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(\"tSVD\")\n",
    "tsvd = TruncatedSVD(n_components=N_COMP, random_state=17)\n",
    "tsvd_results_train = tsvd.fit_transform(X_train)\n",
    "tsvd_results_test = tsvd.transform(X_test)\n",
    "\n",
    "print(\"ICA\")\n",
    "ica = FastICA(n_components=N_COMP, random_state=17)\n",
    "ica_results_train = ica.fit_transform(X_train)\n",
    "ica_results_test = ica.transform(X_test)\n",
    "\n",
    "print(\"GRP\")\n",
    "grp = GaussianRandomProjection(n_components=N_COMP, eps=0.1, random_state=17)\n",
    "grp_results_train = grp.fit_transform(X_train)\n",
    "grp_results_test = grp.transform(X_test)\n",
    "\n",
    "print(\"SRP\")\n",
    "srp = SparseRandomProjection(n_components=N_COMP, dense_output=True, random_state=17)\n",
    "srp_results_train = srp.fit_transform(X_train)\n",
    "srp_results_test = srp.transform(X_test)\n",
    "\n",
    "print(\"Append decomposition components to datasets...\")\n",
    "for i in range(1, N_COMP + 1):\n",
    "    X_train['pca_' + str(i)] = pca_results_train[:, i - 1]\n",
    "    X_test['pca_' + str(i)] = pca_results_test[:, i - 1]\n",
    "    \n",
    "    X_train['ica_' + str(i)] = ica_results_train[:, i - 1]\n",
    "    X_test['ica_' + str(i)] = ica_results_test[:, i - 1]\n",
    "\n",
    "    X_train['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n",
    "    X_test['tsvd_' + str(i)] = tsvd_results_test[:, i - 1]\n",
    "\n",
    "    X_train['grp_' + str(i)] = grp_results_train[:, i - 1]\n",
    "    X_test['grp_' + str(i)] = grp_results_test[:, i - 1]\n",
    "\n",
    "    X_train['srp_' + str(i)] = srp_results_train[:, i - 1]\n",
    "    X_test['srp_' + str(i)] = srp_results_test[:, i - 1]\n",
    "print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05794651 0.03830152 0.03826978 0.03829257 0.03824949 0.03824868\n",
      " 0.03823126 0.03822519 0.03820725 0.03819589 0.02793447 0.02233509\n",
      " 0.01658305 0.01311583 0.01158509 0.01150749 0.01133952 0.01121794\n",
      " 0.0111313  0.01036726 0.00946694 0.00854255 0.00795859 0.00719521\n",
      " 0.00696026 0.00646913 0.00634428 0.00616397 0.00599341 0.00590364\n",
      " 0.00575137 0.00566054 0.00541042 0.0053211  0.00497676 0.00483614\n",
      " 0.00471498 0.0045274  0.00443353 0.00438627 0.00427261 0.00419301\n",
      " 0.00409213 0.00405966 0.00392977 0.00381137 0.00380971 0.00369268\n",
      " 0.00360112 0.00347747 0.00341188 0.00320911 0.00320336 0.00309682\n",
      " 0.00296604 0.00288679 0.0027413  0.00264533 0.00260542 0.00258658\n",
      " 0.00253314 0.00248415 0.00246391 0.00233773 0.00231945 0.00225922\n",
      " 0.00222218 0.00218558 0.00212328 0.00208423 0.00205147 0.00199296\n",
      " 0.00191693 0.00184655 0.00181976 0.0017785  0.00174848 0.00172015\n",
      " 0.00170724 0.00167963 0.00165302 0.00160432 0.00158966 0.0015377\n",
      " 0.00152632 0.00149971 0.00144064 0.00141479 0.00139959 0.00139091\n",
      " 0.00135851 0.00134606 0.00132145 0.00128391 0.00126333 0.00121514\n",
      " 0.00119172]\n",
      "0.8039051351911904\n"
     ]
    }
   ],
   "source": [
    "print(tsvd.explained_variance_ratio_)\n",
    "sum1 = 0\n",
    "for i in range(len(tsvd.explained_variance_ratio_)):\n",
    "    sum1 = sum1 + tsvd.explained_variance_ratio_[i]\n",
    "\n",
    "print(sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8041603444003791\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(len(pca.explained_variance_ratio_)):\n",
    "    sum = sum + pca.explained_variance_ratio_[i]\n",
    "\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48b71bc540cd0acc4a5cff3b2d8263e022bbde63c646d15e8a8dd6ce6c9dde39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
